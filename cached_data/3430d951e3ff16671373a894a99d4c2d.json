"BITS ID: 2023 ACO 246\n\\( c=\\left[\\begin{array}{ccc}1 & 0 & 0 \\\\ 0 & c / b & 0 \\\\ 0 & e / d & f / d\\end{array}\\right]\\left[\\begin{array}{ccc}1 / a & 0 & 0 \\\\ -1 / a & 1 / b & 0 \\\\ -1 / a & 0 & 1 / d\\end{array}\\right] \\)\n2\n\\[\n\\begin{array}{l}\nR_{2} \\times b / c-R_{3} \\\\\nR_{3} \\times d / c=R_{3} \\\\\nC\n\\end{array}=\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 1 & f / c\n\\end{array}\\right]\\left[\\begin{array}{ccc}\n1 / a & 0 & 0 \\\\\n-b / c a & 1 / c & 0 \\\\\n-\\frac{d}{c a} & 0 & 1 / c\n\\end{array}\\right]\n\\]\n\\[\n\\text { Here } A=\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right] \\text { and } B=\\left[\\begin{array}{ccc}\n-1 / a & 0 & 0 \\\\\n-b / c a & 1 / c & 0 \\\\\n\\frac{-c}{f}\\left(\\frac{d+b}{c a}\\right) & -1 / f & 1 / f\n\\end{array}\\right]\n\\]\n\nHence matix \\( B \\) is in the lower triangular form and \\( B \\) is the inverse of \\( A \\) and is lower a lower triongulac matrix\n\nThus, it is practically proved that the inverse of a lower triangular matrix is also a lower triangular matrix.\nthe same can be proned theoretically as follows.\n\nBITS ID: \\( 2023 A C O 5246 \\)\n4\n\nQ2. If an integer \\( n \\) is an eigen value of a squase matrix where all elements of the matrix belong to the set of intagens, prove that the determinant of that matrix is \\( n^{k} \\) where \\( k \\) is an integer.\nSolution: Determination of a square matrix which has \\( n \\) as an eigenvalue is \\( n^{k} \\)\nSo, furst we verte the choracteristic polynomial of mahix. Suppose \\( A \\). then, \\( P(\\lambda)=\\operatorname{det}(\\lambda I-A) \\)\n\nAfter expanding thes determinent, we get a polynomial of degree \\( n \\)\nBy solving thes above prolynomial, we get a rool value which is the eagen value of matrix \\( A \\).\nAlso, the cheracteristic polynomial will be\n\\[\nP(\\lambda)=\\operatorname{det}(\\lambda I-A)-1\n\\]\n\nAfter expanding equation 1 we get\n\\[\n1 \\times \\lambda^{n}+a_{n-1} \\lambda^{n-1}+\\cdots+a_{2}+a_{0}\n\\]\n\nThis is a polynomial \\( \\delta \\) degree \\( w \\), it can be foctured as\n\\[\n\\left(\\lambda-\\lambda_{1}\\right)\\left(\\lambda-\\lambda_{2}\\right)\\left(\\lambda-\\lambda_{3}\\right) \\ldots\\left(\\lambda-\\lambda_{n}\\right)-2\n\\]\nwhere \\( \\lambda_{1}, \\lambda_{2}, \\lambda_{3} \\ldots \\lambda_{n} \\) are roots of this polynomial.\n\\( \\therefore \\) It is the eigen value of this matsix \\( A \\)\n\\( A C=0 \\), equation 1 impilues thet\n\\[\n\\begin{aligned}\nP(0) & =\\operatorname{det}(O-A) \\\\\n& =\\operatorname{det}(-A) \\\\\n& =\\operatorname{det}((-1) \\times(A))-3\n\\end{aligned}\n\\]\n\nRIDA KHAN\nMFML ASSIGNMENT.\n(1)\n\nBITS ID: 2023 AC 05246\nSECTION: B\nSUBJECT: MFML\nASSIGNMENT NO: OI\nQ1. To prove: Inverse of a trianguler matix \\( x \\) is a triangulas matrix.\nProof: let \\( A \\) be a \\( 3 \\times 3 \\) lower hiangular matrix and \\( B \\) be a \\( 3 \\times 3 \\) Identity matrix\nIn the Augmented foum, we know \\( A B=C \\)\n\\[\n\\therefore \\quad c=\\left[\\begin{array}{lll}\na & 0 & 0 \\\\\nb & c & 0 \\\\\nd & e & f\n\\end{array}\\right]\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right]\n\\]\n\nUsing the quass elimination method, we have\n\\[\n\\begin{array}{l}\nR_{1}=1 / a R_{1} \\\\\nR_{2}=1 / b R_{2} \\\\\nR_{3}=1 / d R_{3}\n\\end{array}\n\\]\nwhich makes it as follones:\n\\[\n\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n1 & c / b & 0 \\\\\n1 & e / d & f / d\n\\end{array}\\right]\\left[\\begin{array}{ccc}\n1 / a & 0 & 0 \\\\\n0 & 1 / b & 0 \\\\\n0 & 0 & 1 / d\n\\end{array}\\right]\n\\]\n\nReducing further as \\( R_{2}=R_{2}-R_{1} \\) and \\( R_{3}=R_{3}-R_{1} \\)\n\nBITS \\( 10: 2023 \\hat{3} \\hat{A C} 05 \\hat{2} \\hat{4} 6 \\)\n3\n1. Definition of a lower biangular malix: \\( A_{i j}=0 \\) for all \\( i<j \\). Shis means all the elements above the mam diagonal are zero.\n2. Inverse of a Matrix: The inverse of a matriv \\( \\left(A^{-1}\\right) \\) is defened such that \\( A A^{-1}=I \\), where \\( I \\) is the identity malrix.\n3. Structure of Lower Triangular Matrix: Aersider a lower triangler matrix \\( A=\\left[\\begin{array}{ccccc}a_{11} & 0 & 0 & \\cdots & 0 \\\\ \\vdots & a_{22} & 0 & \\cdots & 0 \\\\ a_{n 1} & a_{n 2} & a_{33} & & 0 \\\\ & a_{n 3} & \\cdots & a_{n n}\\end{array}\\right] \\)\n4. Meltiplication of Matrices. When multiplying theo matrices \\( A \\) and \\( B \\), the element of the ithrow and \\( j^{\\text {th }} \\) column of the product matrit \\( C=A B \\) is given by:\n\\[\nC_{i j}=\\sum_{k=1}^{n} A_{i k} B_{k j}\n\\]\n\nFor a lower sular matrix, this product involven only elements from the lower D'ulare part.\n5. Inverse Calculation: Io show that the inverse of \\( A \\) is also lower hangular, we need to demonstrate that \\( A^{-1} \\) has zeros above the diagonel. Suppose \\( A^{-1}=\\left(a_{i j}^{\\prime}\\right) \\) is not lower triangular, umplyig \\( a_{i j}^{i} \\neq 0 \\) por come \\( i<j \\).\n\nAlso if \\( A \\) is a lower hianguber matrix and \\( A^{-1} \\) is not, then \\( A A^{-1} \\) nould not be an identity maloin because the product would not zero out elements absove the diagond. This contradich the definition of the undentily matrix 1 .\n\nThesefore, \\( A^{-1} \\) must also be cover hiangular metrix to satify \\( A A^{-1}=I \\)\n\nHence proned theoretically.\n\nBITs ID:2023ACO5246\nb) \\( B \\) is a rectangular matrix \\( (n \\times m) \\) :\n6.\n\nHere \\( n \\geqslant m \\), as \\( B \\) has columns that are leneady undependent.\n\\[\n\\therefore \\operatorname{Rank}(A B)=\\operatorname{rank}(B)=m \\text {. }\n\\]\n\n2- Columns of \\( B \\) are linearly dependent if\na) \\( B \\) is a square matrix \\( (n \\times n) \\).\n\\( \\operatorname{rank}(B)<n \\) i.e at least column/iow is a linear combination of the olhen.\n\\[\n\\therefore \\operatorname{Rank}(A B)=\\operatorname{rank}(B)<n \\text {. }\n\\]\nb) \\( B \\) is a rectangular matris \\( (n \\times m) \\)\n\\( \\operatorname{rant}(B)=\\min (n, m) \\) i.e ils less than its demention\n\\( \\therefore \\operatorname{Rank}(A B)=\\operatorname{rank}(B)<n=\\operatorname{rank}(A) \\).\n\\( \\therefore \\) from 1 and 2 , we know thal \\( \\operatorname{Rank}(A B) \\leq \\min (\\operatorname{Rank}(A), \\operatorname{rank}(B)) \\)\n\\( \\therefore \\operatorname{Rank}(A B) \\leq \\min (n, m)=m \\).\nInis umplies that, the rank of \\( A B \\) can never exceed rank of \\( B \\), regardless of \\( A \\).\n\\( \\therefore \\operatorname{Rank} \\) of \\( A B \\) o2 \\( (\\operatorname{Rarlu}(A B)) \\) is determined by the rank of matrix \\( B \\) and \\( \\operatorname{not} A \\).\n\nThis disproves that \\( \\operatorname{rant}(A B)=\\operatorname{Rank}(A) \\) values and the value of the ratio.\n\nMatrix \\( A \\) and its property, \\( A^{2}=8 I \\).\n\nBITS ID: \\( 2023 A C O 5246 \\)\nUsing the property of determinant we have\n\\[\n\\operatorname{det}(k A)=k^{h} \\operatorname{det}(A)\n\\]\n\nFrom eq 3\n\\[\nP(0)=(-1)^{n} \\operatorname{det}(A)\n\\]\n\\( \\qquad \\)\n5\n\nFrom eq 2, we hove\n\\[\n\\begin{aligned}\nP(\\lambda) & =\\left(\\lambda-\\lambda_{1}\\right)\\left(\\lambda-\\lambda_{2}\\right)\\left(\\lambda-\\lambda_{3}\\right) \\ldots\\left(\\lambda-\\lambda_{n}\\right) \\\\\nP(0) & =\\left(-\\lambda_{1}\\right)\\left(-\\lambda_{2}\\right)\\left(-\\lambda_{3}\\right) \\ldots\\left(-\\lambda_{n}\\right) \\\\\n& =(-1)^{n} \\lambda_{1} \\times \\lambda_{2} \\ldots \\lambda_{n} \\quad 5\n\\end{aligned}\n\\]\n\nFrom equation 4 and 5 , we get\n\\[\n\\operatorname{det}(A)=\\lambda_{1} \\times \\lambda_{2} \\times \\lambda_{3} \\times \\cdots \\times d_{n}\n\\]\ngiven that \\( \\lambda_{1}=n_{1} \\) so\n\\[\n\\operatorname{det}(A)=n \\times \\lambda_{2} \\times \\ldots \\times \\lambda n\n\\]\n\nHence proved.\nQ3. If \\( A \\) is an invertible square matrix of order \\( n \\), then prove or dippore thant \\( \\operatorname{ranct}(A)=\\operatorname{rank}(A B) \\)\nSolution: If \\( A \\) is an invertible matrix of order \\( n \\). Shen \\( A \\) has full rant and its columns form a baser of \\( R^{n} \\)\n\\[\n\\text { Therefore, } \\operatorname{ranh}(A)=W\n\\]\n\nThe effect \\( \u20b9 \\) multaplying matrix \\( (A)_{n \\times n} \\) with a matrix \\( (B)_{n \\times m} \\).\n1. The columis of matrix \\( B \\) are linearly Independent if\na) \\( B \\) is a square matriv \\( (n \\times n) \\) :\n\\( B \\) null be meritible as well, with full rank.\n\\( \\therefore \\operatorname{Rank}(A B)=\\operatorname{ran}(A)=\\operatorname{rank}(B)=n \\), as it is prodect 8 twie invicible matrices.\n\nRIDA KHAN\nSECTION: B\n10\n\nBITS 1D: 2023ACO5246\n\\[\n\\Rightarrow C_{1}=0\n\\]\n\\( \\Rightarrow \\) This contradicts our statement \\( -v_{1}, v_{2}-v_{1} \\ldots v n-v_{1} \\) are not emearly dependent\n\\( \\Rightarrow v_{1}, v_{2}-v_{1}, v_{2}-v_{1} \\ldots v_{n}-v_{1} \\) are imearly dependent Hence proved.\n\nRIDA KHAN\nSECTION: B\n9\n\nBITS 10:2023ACOS246\n\\[\n\\begin{array}{l}\n=l(-y-z)+m y=-l y-l z+m y \\\\\n=(m-l) y-l z\n\\end{array}\n\\]\n\\[\n\\Rightarrow \\operatorname{span}\\{x, y\\} \\leqslant \\operatorname{span}\\{y, z\\}\n\\]\n\\( \\operatorname{Span}\\{y, z\\} \\cdot x y+0 z \\)\n\\[\n\\begin{array}{l}\n=n y+0(-x-y)=n y-0 x-0 y \\\\\n=(n-0) y-0 x\n\\end{array}\n\\]\n\\( \\Rightarrow \\operatorname{span}\\{y, z\\} \\leq \\operatorname{spar}\\{x, y\\}-5 \\)\nFrom equation 4 and 5, we have\n\\( \\operatorname{span}\\{x, y\\}=\\operatorname{span}\\{y, x\\} \\quad 6 \\)\nNow, if we compare eq 3 and 6 , we gel\n\\[\n\\operatorname{Span}\\{x, y\\}=\\operatorname{span}\\{y, x\\}=\\operatorname{span}\\{x, z\\}\n\\]\n\nHence proved\nPart (B) Given: Span \\( v \\) having \\( v_{1}, v_{2}, v_{3} \\ldots v_{n} \\) prove that\n\\[\n\\begin{aligned}\nv_{1} & \\left.v_{2}+v_{1}, v_{2}=v_{3}-v_{1}+v_{1} ; v_{n}=v_{n}-v_{1}+v_{1}\\right\\} \\\\\n\\Rightarrow & v=c_{1} v_{1}+c_{2}\\left(v_{2}-v_{1}+v_{1}\\right)+c_{3}\\left(v_{3}-v_{1}+v_{1}\\right) \\ldots c_{n}\\left(v_{n}-v_{1}+v_{1}\\right) \\\\\n\\Rightarrow & v_{1}=c_{1} v_{1}+c_{2}\\left(v_{2}-v_{1}+v_{1}\\right)+c_{3}\\left(v_{3}-v_{1}+v_{1}\\right) \\ldots c_{n}\\left(v_{n}-v_{1}+v_{1}\\right) \\\\\n\\Rightarrow & \\left(c_{1}+c_{2}+c_{3}+\\cdots c_{n}\\right) v_{1}+c_{2}\\left(v_{2}-v_{1}\\right)+c_{3}\\left(v_{3}-v_{1}\\right) \\ldots \\\\\n& +c_{n}\\left(v_{n}-v_{1}\\right)\n\\end{aligned}\n\\]\n\nThis is the linear combination of \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1}+\\ldots, v_{n}-v_{1} \\).\nHence proving \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1} \\ldots v_{n}-v_{1} \\) also belongs to span \\( V \\).\nii) Given \\( v_{1}, v_{2}, v_{3} \\ldots v_{n} \\) are linearly dependent then co efficient must be 0\n\\[\n\\begin{aligned}\n\\Rightarrow & c_{1}-c_{2}-c_{3} \\ldots c_{n}=0 \\\\\n& c_{2}=0, c_{3}-0 \\ldots c_{n}=0 .\n\\end{aligned}\n\\]\n\nBITS ID: 2023 ACO5246\nSol \\( \\rightarrow \\) Given: \\( A^{2}=Q 1 \\)\n7.\n\\( a=1 \\) and \\( b=-1 \\)\nThe given matrix is a symmatric matrix. So we can trove, if \\( \\lambda \\) is an ergenvalue of matrix, \\( \\lambda^{2} \\) is the ergen value if \\( A^{2} \\) as ginen.\n\\( \\lambda \\) is the eigen value of \\( A \\)\n\\( A V=\\lambda V \\) for some \\( V \\neq 0 \\).\nnultiplying \\( A \\) on both sides, we have\n\\[\n\\begin{aligned}\nA(A V) & =A(\\lambda V) \\\\\nA^{2} V & =\\lambda A V \\\\\n& =\\lambda^{2} V\n\\end{aligned}\n\\]\n\nAlso, \\( \\quad A^{2}=Q I \\)\n\\( A^{2}=8 \\times I \\times I \\) [ The product of \\( I \\times I \\) is \\( I \\) ]\n\nTaking equare on b/s we have\n\\[\nA= \\pm 2 \\sqrt{2} 1\n\\]\n\nSo \\( \\frac{d_{\\max }}{\\lambda_{\\min }}=\\frac{2 \\sqrt{2}}{2 \\sqrt{2}}=-1 \\).\nQ.5. Show that if \\( x+y+z=0 \\), then \\( \\operatorname{span}(x, y)=\\operatorname{span}(x, 2)= \\) \\( \\operatorname{span}(y, 2) \\) and if vectors \\( v_{1}, v_{2}, \\ldots v_{x} \\) span \\( v \\), then the vectors \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{2}, \\ldots v_{n}-v_{n-1} \\) also span \\( V \\).\n\nRIDA KHAN\nSECTION: \\( B \\)\n\\( \\theta \\)\n\nBITS 10:2023ACO5246\n\nSol \\( \\rightarrow \\) Span: A span of vectows is the oet of all lenear combenations of thes veitors\nlet \\( x, y, z, \\ldots \\) be linearly independent.\nPart (a): \\( x, y, z \\) are vectors such thal \\( x+y+z=0 \\). We need to prove: \\( \\operatorname{Span}\\{x, y\\}=\\operatorname{span}\\{y, x\\}=\\operatorname{span}\\{x, z\\} \\)\n\\[\n\\begin{array}{l}\nx+y+z=0 \\\\\nx=-(y+z) \\\\\ny=-(x+z) \\\\\nz=-(x+y)\n\\end{array}\n\\]\nfor span \\( \\{x, y\\} \\) and \\( \\{x, z\\} \\)\n\\[\n\\begin{aligned}\n\\operatorname{Span}\\{x, y\\} & =a x+b y \\\\\n& =a x+b(-x-x) \\\\\n& =a x-b x-b x \\\\\n& =(a-b) x-b z\n\\end{aligned}\n\\]\n\\( \\operatorname{Span}\\{x, y\\} \\leq \\operatorname{span}\\{x, z\\}-1 \\)\n\\[\n\\begin{aligned}\n\\operatorname{span}\\{x, z\\} & =(x+d z \\\\\n& =c x+d(-x-y)=c x-d x-d y \\\\\n& =(c-d) x-d y\n\\end{aligned}\n\\]\n\\( \\operatorname{Span}\\{x, z\\} \\leq \\operatorname{span}\\{x, y\\}-2 \\)\nFrom eq 1 and 2\n\\[\n\\operatorname{span}\\{x, y\\}=\\operatorname{span}\\{x, z\\}-3\n\\]\n\\{Since \\( A \\subseteq B \\) and \\( B \\subseteq A \\Rightarrow A=B\\} \\)\nNow for opan \\( \\{x, y\\} \\) and Span \\( \\{y, x\\} \\)\nspan \\( \\{x, y\\}=l x+m y \\)"