"1) If matrix \\( A \\) be a square matrix and \\( B \\in R^{n \\times n} \\) then \\( A B=B A=I \\), \\( B \\) is called inverse of \\( A \\) \\( \\Rightarrow A A^{-1}=A^{-1} A=I \\) where \\( I \\) is identity matrix of\n2) Matrix is only invertible if and only if \\( \\operatorname{det}(A) \\neq 0 \\)\n\nProof \\( \\rightarrow \\) het's suppose \\( L \\) is a lower triangular matrix of order \\( n \\times n \\) and \\( L^{-1} \\) is inverse of \\( L \\)\n(i.e) \\( L=\\left[\\begin{array}{ccccc}l_{11} & 0 & 0 & \\ldots . & 0 \\\\ l_{21} & l_{22} & 0 & \\ldots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ l_{n 1} & \\ln _{n 2} & l_{n 3} & \\cdots & l_{m}\\end{array}\\right]_{n \\times n} \\rightarrow L_{i j}=0 \\) for We need to prove that \\( \\mathrm{L}^{-1} \\) is also a Lower Triangular matrix.\nhet suppose, \\( L^{-1}=M \\) and we will try to verify whether it is \\( L T M \\) or nat. (i.e) (LM) \\( i j=0 \\) for \\( i \\dot{j} \\)\n\\[\nM=\\left[\\begin{array}{cccc}\nm_{11} & m_{12} & \\ldots . & m_{1} \\\\\nm_{21} & \\vdots & \\cdots & \\vdots \\\\\n\\vdots & \\vdots & \\cdots & m_{m n}\n\\end{array}\\right]_{n+n}\n\\]\n\nBared on the property of inverse and equation(9)\n\\( \\Rightarrow L M=I \\) where I is the identity matrix\nA bove equation resumbles E\u0948\u0935(1), where each row of \\( I \\). is equal to linear combiration of rows of \\( M \\) and combining coefficients are from \\( L \\).\nBased on matrix multiplication and \\( \\mathrm{Bq}_{1}(\\mathrm{I} \\), we com derive the following:\n\\[\nI_{i j}=\\sum_{k=1}^{n} l_{i k} m_{k j}\n\\]\n\nFor \\( i<j, l_{i j}=0 \\) (as \\( h \\) is a Lower triangular matrin) For \\( i \\geq j, l i j \\neq 0 \\) (as \\( L \\) is a hower triangular matrix)\nThen, for \\( I_{i j} \\) identity matrix, \\( I_{i j}=\\sum_{k=1}^{n} l_{i k} m_{k j} \\)\n\\[\n\\Rightarrow \\sum_{k=1}^{n} l_{i k} m_{k j}=\\left\\{\\begin{array}{ll}\nk=1 & \\text { if } i \\neq j \\\\\n1 & \\text { if } i=j\n\\end{array}\\right.\n\\]\n\nLet's take one example, where \\( i=1, j=2 I_{12}=\\sum_{k=1}^{n} l_{1 k} m_{k 2} \\)\n\\[\n=l_{11} m_{12}+l_{12} m_{22}+\\ldots \\lim _{m_{12}}\n\\]\n\nConidering lower triangular matrix properties,\n\\[\n\\begin{aligned}\n& l_{12}=l_{13}=l_{14} \\ldots l_{1 n}=0 \\text { for } i c j \\\\\n\\Rightarrow \\quad I_{12}= & l_{11} m_{12}+0\\left(m_{22}\\right)+\\ldots . .0\\left(m_{m 2}\\right) \\\\\n& \\left.=l_{11} m_{12} \\quad \\text { (where } l_{11} \\neq 0 \\text { for } i \\geq j\\right)\n\\end{aligned}\n\\]\n\\( U \\) sing \\&q (4) where \\( i \\neq j, I_{i j}=0 \\)\n\\[\n\\Rightarrow \\quad 0=l_{11} m_{12}\n\\]\n\nWe know that, \\( I_{12}=0 \\) for identity matrix and \\( l_{11} \\neq 0 \\) Hence, in order for I12 to be \\( 0, m_{12} \\) should also be zero.\nNow, we have equation (4) \\( \\sum_{k=1}^{n} l_{i k} m_{k j}=0(i<j) \\) for \\( i<j, l i k \\neq 0 \\) as \\( L \\) is lower triangular matrix\nThat implies, mij mut be zero for \\( k j \\) above the diagonal, making it a lower triangular matrixHence, Inverse of Lower Triongular matrix is LTM.\n(i.e) \\( L_{L T M}=L^{-1}-T M \\)\n\n2) If an integer \\( n \\) is an eigen value of square matrix where all eliments of matrix belongs to the set of integers, the prove that the determinant of that matrix is \\( n k \\) where \\( k \\) is an integer.\nSolution \\( \\rightarrow \\) Given that integer \\( n \\) is an eigen value of square matrix. (i.e) \\( \\lambda_{1}=n \\)\nTo prove, Neterminant of square matrix is \\( n k \\) where\n\\[\n\\Rightarrow \\operatorname{det}(A)=n k\n\\]\nkin an integer\nProof het's suppose \\( A \\) is a square matrix of order \\( n \\times n \\) (i-e) \\( A \\in \\mathbb{R}^{n \\times n} \\).\nWe know that, Properties of eigen values are as follows \\( \\rightarrow \\)\n(1) Characteritic polyromial\neigen values of \\( A \\) are the roots of characteristic palynomial \\( \\operatorname{det}(A-\\lambda I) \\) which is as follows \\( \\rightarrow \\)\n\\[\nP(\\lambda)=\\lambda^{n}+a_{n-1} \\lambda^{n-1}+\\cdots+a_{1} \\lambda+a_{0}\n\\]\nwhere \\( a_{1} \\) are integers\n\\( m \\) indicates degree of poly nomial\n(2) Determinant of matrix is equal to product of eigen values of matrix\n(i.e) \\( \\operatorname{det}(A)=\\prod_{i=1}^{n} \\lambda_{i}(i=1,2 \\ldots 3 \\ldots n) \\)\nwhere \\( \\lambda_{1}, \\lambda_{2} \\ldots \\) are eigen valus of \\( A \\)\nConvidering Eq(b) and subitituting given valves -\n(i\u2022e)\n\\[\n\\begin{array}{l}\n\\operatorname{det}(A)=\\prod_{i=1}^{n} \\lambda_{i} \\\\\n\\operatorname{det}(A)=\\lambda_{1} \\times \\lambda_{2} \\times \\lambda_{3} \\times \\lambda_{4} \\ldots \\lambda_{n}\n\\end{array}\n\\]\n\nMFML ASSIGNMENT 1\nNAME - T.MANASA\nSECTION-04\nBITS ID- 2023ac05423\n1) Using only the idea that in the equation \\( C=A B \\) where \\( C, A, B \\) are \\( n \\times n \\) matrices, the \\( i^{\\text {th }} \\) row of matric \\( C \\) for \\( 1 \\leq i \\leq n \\) is obtoined by taking a linear combination of rous of \\( B \\) where the combining coefficient come form the ith row of \\( A \\), show that the minverse of howes Triangular is a hower Triangular madrix.\nSolution \\( \\rightarrow \\) given that \\( C=A B \\) where \\( C, A, B \\) are \\( n \\times n \\) matrices and ithrow of matrix \\( C \\) for \\( 1 \\leq i \\leq n \\) is Obtained by linear combination of rows \\( B \\) and coeffir where \\( i^{\\text {th }} \\) row and \\( j^{\\text {th }} \\) column\nBased on matrix multiplication, \\( C=A \\times B=A B \\rightarrow 0 \\)\n\\( \\Rightarrow \\) Expand the equation for all the elements which would result in:\nfor \\( i=1, \\quad c_{i j}=c_{11}=a_{11}\\left(b_{11}\\right)+a_{12}\\left(b_{21}\\right)+\\ldots a_{n 1}\\left(a_{1 n}\\right) \\) for \\( \\begin{array}{l}i=1 \\\\ j=2 \\\\ 1\\end{array}, c_{i j}=c_{12}=a_{11}\\left(b_{12}\\right)+a_{12}\\left(b_{22}\\right)+\\cdots c_{2 m}\\left(b_{22}\\right) \\) This leads to the following equation, \\( c_{i j}=\\sum_{k=1}^{n} a_{i k} b_{k j} \\)\n\\( \\overrightarrow{A r i x}^{\\text {(2) }} \\)\nTo prove: that Inverse of a hower triangulor matrix is a lower triangular matrix\nWe know that, Properties of Inverse Matrix are as follows:\n\nConclusion \\( \\rightarrow \\)\n1) If \\( B \\) is a \\( n \\times n \\) square matrix \\( \\& \\) invertible, \\( \\operatorname{rank}(A)=\\operatorname{ramk}(A B) \\)\n2) If \\( B \\) is \\( m+n \\times n \\) non-invertible square matrix\n\\[\n\\text { , } \\operatorname{nank}(A) \\neq \\operatorname{ramk}(A B)\n\\]\n\nHence, statement romk \\( (A)=\\operatorname{rank}(B) \\) is only proven when \\( B \\) is also men invertible square matrix otherwise disproven.\n4) A machine learning researcher comes across the following madrix whle analysing data and ofter Careful study of matrix and its propenties will halp him deing faiter algo ond solve the problem. In the matrix value of \\( a=1 \\) and \\( b=-1 \\). He makes on observation \\( A^{2}=8 I \\). He wants to onswer the follow\na) What are the eigen values of motrix?\nb) What is the value of ratio \\( \\frac{\\lambda(\\max )}{\\lambda(\\min )} \\) ?\n\nGiven \\( \\rightarrow A \\) is a square matrix of order \\( 8 \\times 8 \\). and \\( A^{2}=8 I \\) where \\( I \\) is identity matrix.\nSolution \\( \\rightarrow \\) het \\( A \\) be \\( n \\times n \\) squar matrix (i.e) \\( A \\in R^{n \\times m} \\) and \\( \\lambda \\in R \\) is an cigenvalue of \\( A \\) then eigen value equation is\n\\[\nA \\vec{x}=\\lambda \\vec{x}\n\\]\n\nMultiply \\( A \\) on both sides of equation (1)\n\\[\nA(A \\vec{x})=(\\lambda \\vec{x}) A\n\\]\n\nGiven, \\( \\lambda_{1}=n \\) where \\( n \\) is an integer values\n\\[\n\\Rightarrow \\operatorname{det}(A)=n \\times \\lambda_{2} \\times \\lambda_{3} \\times \\lambda_{4} \\ldots \\lambda_{n} \\rightarrow \\text { (2) }\n\\]\n\nSince all the elements of \\( A \\) are integers, eigen valug of \\( A \\) will also be integen (i-e) \\( \\lambda_{2}, \\lambda_{3}, \\ldots \\lambda_{n} \\) mut be integers. Product of eigen values will also be het's suppose \\( \\lambda_{1} \\times \\lambda_{3} \\times \\ldots \\lambda_{n}=k \\rightarrow \\) (3) integer.\n\nSupstitute (3) in (1) \\( \\Rightarrow \\operatorname{det}(A)=n\\left(\\lambda_{2} \\times \\lambda_{3} \\ldots \\lambda_{n}\\right) \\)\n\\( \\Rightarrow \\operatorname{det}(A)=n k \\) where \\( k \\) is an integer \\& product of eigen\nHence proved, \\( \\operatorname{det}(A)=n k \\) values\n3) If \\( A \\) is an invertible matrix square matrix of order \\( n \\), then prove (or) disprove that \\( \\operatorname{rank}(A)=\\operatorname{rank}(A B) \\). given that \\( A \\) is an invertible square matrix of \\( n \\times n \\)\n(i.e) \\( A n \\times m \\) \\& \\( A A^{-1}=A^{-1} A=I_{m \\times n} \\) where I is an identity matrix.\nBased on properties of Inverse Matrix, \\( \\operatorname{det}(A) \\neq 0 \\).\n(i.e) \\( A \\) has full ramk and ' \\( n \\) ' pivot positions\n\\[\n\\Rightarrow \\text { rank of } A \\text { is } n \\Rightarrow r k(A)=n\n\\]\n\nTo prove, \\( \\operatorname{ramk}(A)=\\operatorname{rank}(A B) \\) We need to convider different cases for matrix \\( B \\) :\n1) If \\( B \\) is \\( n \\times m \\) motrix square matrix and invertible\n2) If \\( B \\) is \\( n \\times n \\) square matrix and not invertible\n\n\\[\n\\Rightarrow A^{2} \\vec{x}=\\lambda(A \\vec{x})\n\\]\n\nSustitute the value of (1) in (2)\n\\[\n\\begin{array}{l}\n\\Rightarrow A^{2} \\vec{x}=\\lambda(\\lambda \\vec{x}) \\\\\n\\Rightarrow A^{2} \\vec{x}=\\lambda^{2} \\vec{x} \\longrightarrow \\text { (3) }\n\\end{array}\n\\]\n\nWe know that, eigen values of \\( A \\) are calculated by wing the characteristic polynomial \\( \\operatorname{det}(A-\\lambda I) \\)\n\\[\n\\text { (i.e) } \\operatorname{det}(A-\\lambda I)=0\n\\]\n\nBring RHS values to left hand side in (3)\n\\[\n\\begin{array}{l}\n\\Rightarrow \\quad A^{2} \\vec{x}=\\lambda^{2} \\vec{x} \\\\\n\\Rightarrow\\left(A^{2}-\\lambda^{2} I\\right) \\vec{x}=\\overrightarrow{0}\n\\end{array}\n\\]\n\\( U \\) sing charactestic equation, \\( \\left|A^{2}-\\lambda^{2} I\\right|=0 \\)\nsubutitute \\( A^{2}=81 \\) (Given value in quertion)\n\\[\n\\begin{array}{l}\n\\Rightarrow\\left|8 I-\\lambda^{2} I\\right|=0 \\\\\n\\Rightarrow \\lambda^{2}=8 \\\\\n\\Rightarrow \\lambda= \\pm 2 \\sqrt{2}\n\\end{array}\n\\]\n\nEigen values of \\( A \\) are \\( \\lambda=2 \\sqrt{2}, 2 \\sqrt{2}, 2 \\sqrt{2}, 2 \\sqrt{2},-2 \\sqrt{2} \\) \\( -2 \\sqrt{2},-2 \\sqrt{2},-2 \\sqrt{2} \\) as the given matrix is \\( 8 \\times 8 \\), we can have at most 8 roots (0r) eigen values of \\( A \\).\nb) Bard on the above solution \\( \\lambda_{\\max }=2 \\sqrt{2} \\& \\)\n\\[\n\\lambda_{\\min }=-2 \\sqrt{2}\n\\]\n\nRatio of \\( \\lambda_{\\max } \\& \\lambda_{\\min }=\\frac{\\lambda_{\\max }}{\\lambda_{\\min }}=\\frac{2 \\sqrt{2}}{-2 \\sqrt{2}}=-1 \\)\n\\[\n\\therefore \\frac{\\lambda_{\\max }}{\\lambda_{\\min }}=-1\n\\]\n\nConcider the properties of rank, Rank of product of two matrices is equal to \\( \\operatorname{rank}(A B) \\leq \\operatorname{main}(\\operatorname{rark}(A) \\)\n\\[\n\\begin{array}{c}\n\\Rightarrow \\operatorname{ramk}(A B) \\leq \\min (\\operatorname{ramk}(A), \\operatorname{rank}(B)) \\\\\n\\text { Given that } A \\text { is invertible, } \\operatorname{rank}(A)=n\n\\end{array}\n\\]\n, \\( r a n k(B)) \\)\nGiven that \\( A \\) is invertible, ramk \\( (A)=n \\)\nSubutituting, \\( \\operatorname{rank}(A B) \\leq \\min (n, \\operatorname{ramk}(B)) \\)\nCaus I: If \\( B \\) is invertible and square matrix of \\( n \\times m \\) Bnxm (i.e) \\( B B^{-1}=B^{-1} B=I_{n \\times m} \\)\nBased on properties of invertible matrix, \\( \\operatorname{det}(B) \\neq 0 \\)\n(i.e) \\( B \\) has full rank and ' \\( n \\) ' pinot positions\n\\[\n\\Rightarrow \\operatorname{rank} \\text { of } B i n \\Rightarrow r k(B)=n\n\\]\n\nSubutute (8) in (1) \\( \\Rightarrow \\operatorname{ramk}(A B) \\leq \\min (n, n) \\)\nThat implies, Multiplying by \\( B \\) does not change the ramk\nHence, \\( \\operatorname{rank}(A)=\\operatorname{rank}(A B) \\) if \\( B \\) is square \\& invertible matrix\nCase II: If \\( B \\) is not invertible and square matrix of nem Bren (i.e) \\( \\operatorname{det}(B)=0 \\) of \\( n \\times m \\)\nthat means B has a leas romk than \\( n \\), het's say\n\\[\n\\operatorname{ramk}(B)=r \\quad \\text { wherer } \\angle n\n\\]\n\nSubutituting (3) in (1) will yield,\n\\[\n\\begin{array}{l} \n\\quad \\operatorname{rank}(A B) \\leq \\min (n, r) \\text { where } r<n \\\\\n\\Rightarrow \\quad \\operatorname{rank}(A B)=r=\\operatorname{rank}(B)\n\\end{array}\n\\]\n\nHence, \\( \\operatorname{rank}(A B)=\\operatorname{ramk}(B) \\) if \\( B \\) is \\( n \\times n \\) square matrix and non-invertible.\n\n5) Let \\( x, y, z \\) be three vectors in a vector space \\( V \\).\na) Show that \\( x+y+z=0 \\) then span \\( \\{x, y\\}=\\operatorname{sporn}\\{x, z\\} \\)\n\\[\n=\\operatorname{spam}\\{y, z\\}\n\\]\n\nGiven that, \\( x+y, z \\) are three vectors in \\( V \\)\n\\[\n\\begin{array}{l}\n\\text { (i.e) } x \\in V, y \\in V, z \\in V \\\\\n\\& x+y+z=0\n\\end{array}\n\\]\n\nTo prove \\( \\rightarrow \\operatorname{spom}\\{x, y\\}=\\operatorname{span}\\{x, z\\}=\\operatorname{span}\\{y, z\\} \\)\nProof Definition of Spam \\( \\rightarrow \\) Set of all vectors trat cambe expresed as linear combination of these vectors:\n(i.e) \\( \\operatorname{spon}\\left\\{\\nu_{1}, \\nu_{2} \\ldots \\nu_{k}\\right\\}=\\left\\{\\sum_{i=1}^{k} c_{i} \\nu_{i} \\quad \\begin{array}{ll} & \\text { where } c_{i} \\in R \\\\ & \\text { and a scalar }\\end{array}\\right. \\)\n\nStep 1: Prove \\( \\operatorname{spam}\\{x, y\\}=\\operatorname{spom}\\{x, z\\} \\)\nConvider the given equation, \\( x+y+z=0 \\)\n\\[\n\\begin{array}{rl}\n\\Rightarrow z=-x-y(\\text { or }) ~ & y=-x-z \\\\\n\\rightarrow(1)\n\\end{array}\n\\]\n\\[\n\\begin{array}{l} \n\\text { Spom }\\{x, y\\}=\\sum_{d=1}^{k} c_{i} v_{i} \\\\\n=c_{1} x+c_{2} y=c_{1} x+c_{2}(-x-z) \\\\\n=\\left(c_{1}-c_{2}\\right) x+\\left(-c_{2}\\right) z \\text { where } c_{1}-c_{2}, c_{2} \\\\\n\\text { are scalars }\n\\end{array}\n\\]\n\nThis shous that span \\( \\{x, y\\} \\) com be expresed allinear combiration of \\( x \\) and \\( z \\) (i.e) spon \\( \\{x, y\\} \\subseteq \\operatorname{spon}\\{x, z\\} \\)\nComputing spom \\( \\{x, z\\}=c_{1} x+c_{2} g^{z} \\rightarrow \\) (3)\nSubutitute (2) in (3)\n\\[\n\\operatorname{spom}\\left\\{x_{1} z\\right\\}=c_{1} x+c_{2}(-x-y)=\\left(c_{1}-c_{2}\\right) x+\\left(-c_{2}\\right) y\n\\]\n\nThis shows that span \\( \\{x, z\\} \\) com be eppresed as linear combination of \\( x \\) and \\( y \\).\n\nThat implies, spon \\( \\{x, y\\}=\\operatorname{spom}\\{x, z\\} \\) Barcluded Bared on Step 1\nStep2: Prove spom \\( \\{x, y\\}=\\operatorname{spom}\\{y, z\\} \\) Concider the equation, \\( x+y+z=0 \\)\nComputing\n\\[\nx=-y-z \\text { (or) } z=-x-y\n\\]\nspom \\( \\{x, y\\}=c_{1} x+c_{2} y \\)\n\\[\n=c_{1}(-y-2)+c_{2} y\n\\]\n\\( =\\left(c_{1}-c_{2}\\right) y+\\left(-c_{2}\\right) z \\) where \\( c_{1}-c_{2}, \\cdot c_{2} \\)\nare scalare\nThis shours that spom \\( \\{x, y\\} \\) cam be expresed as linear combination of \\( y \\) and \\( z \\)\n\\[\n\\begin{aligned}\n\\text { Computing } \\operatorname{spom}\\{y, z\\} & =c_{1} y+c_{2} z \\\\\n& =c_{1} y+c_{2}(-x-y)\n\\end{aligned}\n\\]\n\\( =\\left(-c_{2}\\right) x+\\left(c_{1}-c_{2}\\right) \\) y where \\( c_{1}-c_{2}, c_{2} \\)\nThis shows that, spom \\( \\{x, y\\}= \\) spom \\( \\{y, z\\} \\) concluded bared on Step2\nStep 3: Prove spom \\( \\{x, z\\}=\\operatorname{spom}\\{y, z\\} \\)\nConcider equation, \\( x+y+z=0 \\)\n\\[\nx=-y-z \\text { (ox) } y=-x-z\n\\]\n\\[\n\\begin{aligned}\n\\text { Computing spom }\\{x, z\\}=c_{1} x+c_{2} z & =c_{1}(-y-z)+c_{2} z \\\\\n& =\\left(c_{1}-c_{2}\\right) y+\\left(-c_{2}\\right) z\n\\end{aligned}\n\\]\n\nThis shous that spon \\( \\{x, z\\} \\) com also be expreved as linear combination of \\( y \\mathrm{and} z \\)\n\\[\n\\text { Computing spom }\\left\\{\\begin{aligned}\n\\text { Com, } z\\} & =c_{1} y+c_{2} z=c_{1}(-x-z)+c_{2} z \\\\\n& =\\left(-c_{1}\\right) x+\\left(c_{1}-c_{2}\\right)\n\\end{aligned}\\right.\n\\]\nwhere \\( C_{1}, C_{1}-C_{2} \\) are bcalar\n\nThis shows that spom \\( \\{y, z\\} \\) can be expreverd as linear combination of \\( x \\) and \\( z \\)\nThat implies, \\( \\operatorname{spom}\\{x, z\\}=\\operatorname{spom}\\{y, z\\} \\)\nConcluded\nBased on step 3\nHence, Bard on Step 1, Step 2, Step 3\n\\[\n\\Rightarrow \\operatorname{spom}\\{x, y\\}=\\operatorname{spom}\\{x, z\\}=\\operatorname{spom}\\{y, z\\}\n\\]\n\n5 b) Suppose that vectors \\( \\nu_{1}, \\nu_{2}, \\nu_{3} \\ldots \\nu_{n} \\) sporr \\( V \\). Show that the vetars \\( \\nu_{1}, \\nu_{2}-\\nu_{1}, \\nu_{3}-\\nu_{1} \\ldots \\nu_{n}-\\nu_{1} \\) also spom \\( v \\). Show that if \\( \\nu_{1}, \\nu_{2} \\ldots \\). \\( \\nu_{n} \\) are linearly independent. \\( \\nu_{1}, \\nu_{2}, \\nu_{1}, \\ldots \\nu_{n}-\\nu_{1} \\) are also linearly independent.\nGiven that: \\( \\nu_{1}, \\nu_{2} \\ldots \\nu_{n} \\) spam \\( v \\) (i.e) \\( \\nu_{2}=\\nu_{2} \\in \\nu_{s} v \\)\n\\[\nV=\\operatorname{spom}\\left\\{\\nu_{1}, \\nu_{2} \\ldots \\nu_{n}\\right\\}=c_{1} \\nu_{1}+c_{2} \\nu_{2}+\\ldots c_{n} \\nu_{n}\n\\]\nwhere \\( c_{1}, c_{2} \\ldots c_{n} \\) are\nPart 1: To prove \\( \\left\\{\\nu_{1}, \\nu_{2}-\\nu_{1}, \\nu_{3}-\\nu_{1} \\ldots \\nu_{n}-\\nu_{1}\\right\\} \\) spoms \\( V \\) Bared on the given information,\n\\[\nV=b_{1} c_{1} \\nu_{1}+c_{2} \\nu_{2}+c_{3} \\nu_{3}+\\cdots c_{n} \\nu_{n} \\rightarrow \\text { (1) }\n\\]\n\nModify \\( \\varepsilon \\) (1) in a way that \\( \\nu_{2}, \\nu_{3} \\) are represented in terms of \\( v_{1} \\)\n\\[\n\\begin{array}{l}\n\\Rightarrow V=c_{1} \\nu_{1}+c_{2}\\left(\\nu_{2}+\\nu_{1}-\\nu_{1}\\right)+c_{3}\\left(\\nu_{3}+\\nu_{1}-\\nu_{1}\\right)+\\cdots \\\\\nC_{n}\\left(\\nu_{n}-\\nu+\\nu_{1}\\right) \\\\\n=c_{1} \\nu_{1}+c_{2} \\nu_{2}+c_{2} \\nu_{1}-c_{2} \\nu_{1}+\\cdots c_{n} \\nu_{n}-c_{m} \\nu_{1} \\\\\n+\\mathrm{C}_{n} \\nu_{1} \\\\\n=c_{1} \\nu_{1}+c_{2} \\nu_{1}+c_{2}\\left(\\nu_{2}-\\nu_{1}\\right)+\\ldots c_{n} \\nu_{n}-c_{n} \\nu_{1} \\\\\n=\\left(c_{1}+c_{2}+\\ldots c_{n}\\right) \\nu_{1}+c_{2}\\left(\\nu_{2}-\\nu_{1}\\right)+\\ldots\n\\end{array}\n\\]\n\nDistributing the terms,\n\\[\n\\Rightarrow c_{1} \\nu_{1}+c_{2} \\nu_{2}-c_{2} \\nu_{1}+c_{3} \\nu_{3}-c_{3} \\nu_{1}+\\ldots c_{n} \\nu_{n}-c_{n} \\nu_{1}\n\\]\n\\( \\Rightarrow \\) Collecting coefficients\n\\[\n\\left(c_{1}-c_{2}-c_{3}-c_{4} \\ldots c_{n}\\right) \\nu_{1}+c_{2} \\nu_{2}+\\ldots c_{n} \\nu_{n}\n\\]\n\nSince \\( \\nu_{1}, \\nu_{2}, \\nu_{3} \\ldots \\nu_{n} \\) are linearly independent.\nOnly solution to this equation is \\( c_{1}-c_{2}-c_{3} \\ldots-c_{n}=0 \\)\n\\[\nc_{2}=0\n\\]\n\\[\nc_{n}=0\n\\]\n\nSubutitute \\( c_{2}=0, c_{3}=0, \\ldots, c_{n}=0 \\) in (3)\n\\[\nc_{1}=0\n\\]\n\nHence, only solution to this equation is\n\\[\n\\begin{array}{l}\nc_{1} \\nu_{1}+c_{2} \\nu_{2}+c_{3} \\\\\nc_{1} \\nu_{1}+c_{2}\\left(\\nu_{2}-\\nu_{1}\\right)+c_{3}\\left(\\nu_{3}-\\nu_{1}\\right)+\\cdots c_{n}\\left(\\nu_{n}-\\nu_{1}\\right)=0\n\\end{array}\n\\]\n\\[\n\\text { is } c_{1}=c_{2}=\\cdots c_{n}=0\n\\]\n\nHence proved, \\( \\left\\{v_{1}, \\nu_{2}-v_{1}, v_{3}-\\nu_{1} \\ldots v_{n}-v_{1}\\right\\} \\) are hinearly independent.\n\n\\[\n\\begin{aligned}\n& +c_{n}\\left(\\nu_{n}-\\nu_{1}\\right) \\\\\n\\Rightarrow V=\\left(c_{1}+c_{2}+c_{3}-c_{n}\\right) \\nu_{1} & +c_{2}\\left(\\nu_{2}-\\nu_{1}\\right)+c_{3}\\left(\\nu_{3}-\\nu_{1}\\right) \\\\\n+\\ldots & \\ldots\\left(\\nu_{n}-\\nu_{1}\\right)\n\\end{aligned}\n\\]\n\nLet \\( c_{1}+c_{2}+c_{3}-c_{n}=b_{1} \\)\n\\[\n\\begin{array}{l}\nc_{2}=b_{2} \\\\\nc_{3}=b_{3} \\\\\n\\vdots \\\\\nc_{n}=b_{n}\n\\end{array}\n\\]\n\nSubutitute values in above equation \\( \\rightarrow \\)\n\\[\n\\Rightarrow V=b_{1} \\nu_{1}+b_{2}\\left(\\nu_{2}-\\nu_{1}\\right)+b_{3}\\left(\\nu_{3}-\\nu_{1}\\right)+\\ldots b_{n}\\left(x_{n}-\\nu_{1}\\right)\n\\]\n\nThes shous that \\( V \\) eas be expresed as linear combina -tion of \\( \\nu_{1}, \\nu_{2}-\\nu_{1}, \\nu_{3}, \\nu_{1} \\ldots \\nu_{n}-\\nu_{1} \\). where \\( b_{1}, b_{2} \\) ...bn are salars\nHence.froved, \\( \\left\\{\\nu_{1}, \\nu_{2}-\\nu_{1}, \\nu_{3}, \\nu_{1} \\ldots \\nu_{n}-\\nu_{1}\\right\\} \\) spome \\( V \\).\nPart2: \\( \\nu_{1}, \\nu_{2} \\ldots \\nu_{n} \\) are linearlyindependent.\nTo prove \\( \\nu_{1}, \\nu_{2}, \\nu_{1} \\ldots \\ldots \\nu_{n}-\\nu_{1} \\) are also linearly independent.\nLinear Independent \\( =\\sum_{i=1}^{k} C_{i} \\nu_{i}=0 \\) where all \\( c_{i}=0 \\) heveraging the undertanding of eq(1) to given inform\n\\[\n\\Rightarrow \\quad c_{1} \\nu_{1}+c_{2} \\nu_{2}+\\ldots c_{n} \\nu_{n}=0\n\\]\nwhere \\( c_{1}=0, c_{2}=0, c_{n}=0 \\)\n\\( \\left[\\operatorname{as} \\nu_{1}, \\nu_{2} \\ldots \\nu_{n}\\right. \\)\nare hinearly ind pen - dent]\n\nTo prove: \\( \\left\\{\\nu_{1}, \\nu_{2}-\\nu_{1}, \\nu_{3}-\\nu_{1} \\ldots \\nu_{n} \\nu_{1}\\right\\} \\) are aloo Liruan indeperdent.\nComider,\n\\[\n\\begin{aligned}\nc_{1} \\nu_{1}+c_{2}\\left(\\nu_{2}-\\nu_{1}\\right)+ & c_{3}\\left(\\gamma_{3}-\\nu_{1}\\right)+\\cdots \\\\\n& +c_{n}\\left(\\nu_{n}-\\nu_{1}\\right)\n\\end{aligned}\n\\]"