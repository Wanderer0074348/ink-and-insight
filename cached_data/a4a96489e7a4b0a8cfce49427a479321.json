"(D)\nkarishma Kotion\n2033ac05600@wip.bite - pit anit\n(3) If \\( A \\) is an invertible square matrix of order \\( n \\) the prove or disprove that \\( \\operatorname{rank}(A)=\\operatorname{rank}(A B) \\)\n\\( \\Rightarrow \\quad \\because A \\) is an invertible matrix \\( n \\times n \\quad \\therefore \\operatorname{rank}(\\mathbb{A})=n \\) and \\( \\operatorname{rank}(A B) \\leqslant \\min (\\operatorname{rank}(A) \\), \\( \\operatorname{rank}(B)) \\)\nConsidering \\( B \\) is a non singular matrix then \\( \\operatorname{rank}(B)=n \\)\n\\[\n\\begin{array}{l}\n\\operatorname{rank}(A B) \\leqslant \\min (\\operatorname{rank}(A), \\operatorname{rank}(B)) \\\\\n\\operatorname{rank}(A B)=n \\\\\n\\therefore \\operatorname{rank}(A)=\\operatorname{rank}(A B)\n\\end{array}\n\\]\n\nConsidering \\( B \\) is a singular matrix\nthen \\( \\operatorname{rank}(B) \\neq n \\)\n\\[\n\\therefore \\quad \\operatorname{rank}(A B) \\neq n .\n\\]\n\\( \\therefore \\operatorname{rank}(A B) \\Rightarrow \\operatorname{rank}(A) \\).\n(4) Given matrix \\( A \\) and \\( a=1, b=1 \\)\n\\[\nA^{2}=8 I\n\\]\n(a) Finding eigen values of \\( A \\)\n\\[\n\\text { ie } \\quad(A-2 \\sqrt{2} I)(A+2 \\sqrt{2} I)=0 .\n\\]\nthis is a form of characteristic porlynomial\n\\[\n\\begin{array}{l}\n(A-\\lambda . I)(\\operatorname{Al} C(A) I) \\\\\nA(\\lambda)=(A-\\lambda \\neq) \\\\\n\\therefore \\quad \\therefore \\lambda= \\pm 2 \\sqrt{2} \\quad[\\because \\text { eigen values } \\lambda \\text { of } A\n\\end{array}\n\\]\n\\[\n\\text { must satisfy } \\lambda^{2}=8\n\\]\n(b) Calculate the ratio of largest and smallest eigen value\n\nLargest eigen value is \\( 2 \\sqrt{2} \\)\nsmallest eigen value is \\( -2 \\sqrt{2} \\)\n\\[\n\\left|\\frac{\\lambda_{\\max }}{\\lambda_{\\min }}\\right|=\\left|\\frac{2 \\sqrt{2}}{-2 \\sqrt{2}}\\right|=1\n\\]\n\nKarishma Kotian 20230c05600@wilprits pilani.cein\nMFML - Assignment 1\n(1) To show that the inverse of a lower triangular matrix is also a lower triangular matrix we can use the property of matrix multiplication and the structure of a lower triangular matrix.\n\\( \\Rightarrow \\) A lower triangular matrix \\( L \\) is a square matrix in which all the entries above the main diagonal are zero ie \\( L_{i j}=0 \\) for \\( i<j \\)\n\\[\nL=\\left[\\begin{array}{cccccc}\nL_{11} & 0 & 0 & \\cdots & \\cdots & L_{1 n}=0 \\\\\nL_{21} & L_{22} & 0 & \\ldots & 0 & L_{2 n}=0 \\\\\nL_{31} & L_{32} & L_{33} & 0 & \\cdots & L_{3 n}=0 \\\\\n\\vdots & \\vdots & \\vdots & 0 & \\cdots & 1 \\\\\nL_{n 1} & L_{n 2} & L_{n 3} & 0 & \\cdots & h_{n n}\n\\end{array}\\right]\n\\]\n\\( n \\times n \\)\nSuch that \\( L L^{-1}=I \\)\nLet \\( L^{-1}=U \\) where \\( U_{\\text {is }} n \\times n \\) matrix.\nToprone: \\( \\quad U_{i j}=0 \\) for \\( i<j \\)\nMatrix Multiplication rule,\nFor matrix \\( A \\in R^{\\text {mixn }}, B \\in R^{\\text {nxk }} \\) the elements \\( C_{i j} \\) of the product \\( C=A B \\in R^{m \\times k} \\) are computed as\n\\[\nc_{i j}=\\sum_{l=1}^{n} a_{i l} \\cdot b_{i j}, \\quad i=1 \\ldots . J_{M}\n\\]\n\nSo in this case\n\\[\n(L U)_{i j}=\\sum_{k=1}^{n} L_{i k} \\cdot U_{k j}\n\\]\n\nSince \\( L \\) is a lower triangular matrix,\n\\[\nL_{i k}=0 \\text {. for } k>i\n\\]\nwhich means dot product (LU) \\( { }_{i j} \\) will only depent on the entries \\( L_{i j} \\cdot u_{k j} \\) which arefor \\( k \\leq i \\)\n\\( 10(\\alpha U)_{i j}=\\sum_{k=1}^{i} \\alpha_{i k} \\cdot u_{k j} \\)\n\nKarishma Kotian 2023ac05600@wilp.bitspilani.acin\nQ.2) If an integer \\( M \\) is an eigen value of squase matrix where all elements of a matrix belong to the sit of integers then prove that determinant of that matrix is \\( n k \\) where \\( k \\) is an indeger.\n\\( \\Rightarrow \\) Given that,\n\\( A \\) is a square matrix\n\\[\nA=\\left[\\begin{array}{cccc}\na_{11} & a_{12} & a_{13} & \\cdots \\\\\n\\vdots & & & a_{n} \\\\\na_{n 1} & a_{n_{2}} & a_{n_{3}} & \\cdots \\\\\na_{n n}\n\\end{array}\\right]_{n \\times n}\n\\]\n\\( \\operatorname{det}(A-\\lambda I)=P(\\lambda) \\ldots \\) characteristic polynomial\n\\[\nP(\\lambda)=\\left(\\lambda-\\lambda_{1}\\right)\\left(\\lambda-\\lambda_{2}\\right) \\cdots\\left(\\lambda-\\lambda_{n}\\right)\n\\]\nwhere \\( \\lambda_{1}, \\lambda_{2}, \\lambda_{3} \\) are the roots of the characteristic polynomial\n\\[\n\\text { If } \\begin{aligned}\n\\lambda & =0 \\\\\nP(0) & =\\operatorname{det}(A) \\\\\n& =\\left(-\\lambda_{1}\\right) \\cdot\\left(-\\lambda_{2}\\right)\\left(-\\lambda_{3}\\right) \\ldots\\left(-\\lambda_{n}\\right) \\\\\n& =(-1)^{n} \\lambda_{1} \\cdot \\lambda_{2} \\ldots \\lambda_{n}\n\\end{aligned}\n\\]\n\\( n \\) is the eigen value of matrix \\( A \\).\nLet \\( \\lambda_{1}=n \\)\n\\[\n\\operatorname{det}(A)=(-1)^{n} n \\lambda_{2} \\cdot \\lambda_{3} \\ldots \\lambda_{n}\n\\]\nassuming \\( (-1)^{n} \\cdot \\lambda_{2} \\cdot \\lambda_{3} \\ldots A_{n} \\) be \\( k \\) as an integer\n\\[\n\\text { then } \\operatorname{det}(A)=n \\cdot k\n\\]\n\nKarishma Kohom.\n2023ac05600@wilp.bits-pilani. aci\u00f3n\nfor \\( i<j \\)\n\\[\n(L U)_{\\ddot{y}}=\\sum_{k=1}^{i} L_{i k} \\cdot U_{k j}=0 \\quad\\left[\\begin{array}{c}\n\\because L U=I \\\\\ni=j \\Rightarrow I_{y^{ \\pm}}=1 \\\\\ni\\left\\langle I_{i j}=0\\right. \\\\\ni>j=I_{i_{j}}=0\n\\end{array}\\right]\n\\]\n\nSince \\( \\alpha_{i} \\neq 0 \\) for \\( k \\leq i \\), for the abone sum to bezeso \\( u_{k j} \\) has to be zero for all \\( k \\leqslant i \\)\n\nIn particular, \\( u_{i j}=0 \\) for \\( i<j \\)\nIf \\( i<j \\) of \\( u_{i j}=0 \\), then \\( u \\) is a lowertriangular matrix as all its above element above the main diagonal is jero\n\nHence the prouf inverse of a lower triangular matrix is a lower triangular matrin.\n\\[\n\\begin{array}{l}\n\\text { Es to verify } \\\\\nA=\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n1 & 2 & 0 \\\\\n2 & 3 & 3\n\\end{array}\\right] \\\\\n\\begin{array}{c}\nR_{3}-2 R_{1}\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 2 & 0 \\\\\n0 & 3 & 3\n\\end{array}\\right] \\quad A^{-1}=I \\\\\n\\end{array} \\\\\nR_{2 / 2}\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 1 & 1\n\\end{array}\\right] \\quad A^{-1}=\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n-1 / 2 & 1 / 2 & 0 \\\\\n-2 / 3 & 0 & 1 / 3\n\\end{array}\\right] \\\\\nR_{3}-R_{2}\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right] A^{+}=\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n-1 / 2 & 1 / 2 & 0 \\\\\n-7 / 6 & -1 / 2 & 1 / 3\n\\end{array}\\right]\n\\end{array}\n\\]\n\nKarishma Koflan 2023ac05600@wilp.bits-pilani.\n\nQ:5) Ginen \\( x, y, z \\) are nectors in a nectorspace \\( V \\)\n\\[\n\\begin{aligned}\n& x+y+z=0 \\\\\n\\therefore \\quad z & =-x-y\n\\end{aligned}\n\\]\nany vehor in span \\( \\{x, y\\} \\) can be expressed as\n\\[\nx_{1} x+x_{2} y\n\\]\nsubsituting \\( z=-x-y \\), any vechor in\nSpan \\( \\left\\{y_{1} z\\right\\} \\) can be written as\n\\[\n\\begin{aligned}\n\\alpha_{3} y+\\alpha_{4} z & =\\alpha_{3} y+\\alpha_{4}(-x-y) \\\\\n& =\\alpha_{3} y-\\alpha_{4} x-\\alpha_{4} y \\\\\n& =-\\alpha_{4} x+\\left(\\alpha_{3}-\\alpha_{4}\\right) y\n\\end{aligned}\n\\]\n\nTherefore \\( \\operatorname{span}\\{y, z\\} \\subset \\operatorname{span}\\{x, y\\} \\).\n\\( 111^{\\text {ly }} \\), any vector in span \\( \\{x, y\\} \\) can be expressed as\n\\[\n\\begin{aligned}\n\\alpha_{1} y+\\alpha_{2} z & =\\alpha_{1} y+\\alpha_{2}(-x-y) \\\\\n& =-\\alpha_{2} x+\\left(\\alpha_{1}-\\alpha_{2}\\right) y\n\\end{aligned}\n\\]\n\\( \\therefore \\operatorname{span}\\{x, y\\} \\leq \\operatorname{span}\\{3, y, z\\} \\)\n\\( \\sin a \\operatorname{span}\\left\\{y_{1} z\\right\\} \\leq \\operatorname{span}\\{x, y\\} \\& \\operatorname{span}\\{x, y\\} \\frac{c}{c} \\) span \\( \\{y, z 2 \\)\n\\( \\operatorname{Span}\\{x, y\\}=\\operatorname{span}\\{y, z\\} \\)\nUl'y any rector in span \\( \\{y, z\\} \\) cand be writem\n\\[\n\\text { as } \\left.\\beta_{1} y+\\beta_{2} z \\quad\\left(\\beta_{1} ; \\beta_{2} \\quad \\forall \\text { scalas }\\right]\\right)\n\\]\n\nSubstituting \\( y=-x-z \\)\nany vechors in span \\( \\{2, x\\} \\) can be written as\n\\[\n\\begin{aligned}\n\\beta_{3} z+\\beta_{1} x & = \\\\\n\\beta_{1} y+\\beta_{2} z & =\\beta_{1} y-\\beta_{1}-\\beta_{1} z+\\beta_{2} z \\\\\n\\beta_{2} y+\\beta_{2} z & =(-x-z) y \\\\\n\\beta_{1} y+\\beta_{2} z & =(-x-z) \\beta_{1}+\\beta_{2} z \\\\\n& =-x \\beta_{1}-\\beta_{1} z+\\beta_{2} z \\\\\n& =-\\beta_{1}-\\left(\\beta_{1}-\\beta_{2}\\right) z\n\\end{aligned}\n\\]\n\nKohian Karishma\n2023ac05600@wilp.bits-pilani.\n\\( \\therefore \\) Lineare compination,\n\\( \\beta_{1} v_{1}+\\beta_{2}\\left(v_{2}-v_{1}\\right)+\\beta_{3}\\left(v_{3}-v_{1}\\right)+\\cdots \\beta_{n}\\left(v_{n}-v_{1}\\right)=0 \\)\n\\( \\left(\\beta_{1} v_{1}-\\beta_{2} v_{1}-\\beta_{3} v_{1} \\ldots \\beta_{n} v_{1}\\right)+\\beta_{2} v_{2}+\\beta_{3} v_{3} \\ldots+\\beta_{n} v_{n}=0 \\)\n\\( \\left(\\beta_{1} \\ldots \\beta_{2} \\cdots \\beta_{n}\\right) V_{1}+\\beta_{2} V_{2}+\\beta_{3} v_{3}+\\ldots \\beta_{n} v_{n}=0 \\)\n\\( \\because v_{1}, v_{2}, v_{3} \\) are linearly independent there exists only one solution i.e\n\\[\n\\begin{array}{l}\n\\left(\\beta_{1}-\\beta_{2}-\\beta_{3}-\\beta_{n}\\right)=0 \\\\\n\\beta_{2}=0, \\quad \\beta_{n}=0 \\quad \\therefore \\beta_{1}=0\n\\end{array}\n\\]\n\\( \\therefore \\) Vectors \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1} \\ldots v_{n-1} \\) are lineably independent if \\( v_{1}, v_{2}, v_{3} \\ldots v_{n} \\) are linearly independent.\n\nkokan karshma\n20:30105600@wilp.bits-pilaris\n\\( \\therefore \\quad \\operatorname{span}\\{z, x\\} \\subseteq \\operatorname{span}\\{y, z\\} \\)\n111 any vector in span \\( \\left\\{z_{1} x\\right\\} \\) can be cupressed as\n\\[\n\\begin{aligned}\n\\alpha z+\\beta x & =\\alpha(-x-y)+\\beta x \\\\\n& =-\\alpha x-\\alpha y+\\beta x\n\\end{aligned}\n\\]\n\\( \\therefore \\operatorname{span}\\{y, z\\} \\subseteq \\operatorname{span}\\{z, x\\} \\)\n\\( \\therefore \\because \\operatorname{span}\\{z,-x\\} \\subseteq \\operatorname{span}\\{y, z\\} \\quad \\) \\&\n\\( \\operatorname{span}\\{y, z\\} \\) o span \\( \\{z, x\\} \\)\n\\[\n\\therefore \\operatorname{span}\\{y, z\\}=\\operatorname{span}\\{z, x\\}\n\\]\n\nHence \\( \\operatorname{span}\\{x, y\\}=\\operatorname{span}\\{y, z\\}=\\operatorname{span}\\{z, x\\} \\) /\n5(b) \\( v_{1}, v_{2} \\ldots v_{n} \\operatorname{span} V \\)\nToprove:- (i) \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1} \\ldots v_{n}-v_{1} \\in \\operatorname{span} V \\).\n(i) \\( V_{1}, V_{2} \\ldots v_{n} \\) are linearly independent and \\( v_{1}, v_{2}-v_{1} \\ldots v_{n}-v_{1} \\) are also linearlyidependent\n\\( \\Rightarrow \\) ('1) Let \\( w \\) be any vector in \\( v \\) then\n\\[\n\\omega=\\alpha_{1} v_{1}+\\alpha_{2} v_{2}+\\cdots+\\alpha_{n} v_{n}\n\\]\nany \\( V_{i} \\) vector can be rewritten as\n\\[\n\\begin{array}{l} \nv_{i}=\\left(v_{i}-v_{1}\\right)+v_{1} \\\\\n\\therefore w=\\alpha+v_{1}+\\alpha_{2}\\left(v_{2}-v_{1}+v_{1}\\right)+\\ldots \\\\\n\\quad+\\alpha_{n}\\left(v_{n}-v_{1}+v_{1}\\right) \\\\\n\\therefore w=\\left(\\alpha_{1}+\\alpha_{2}+\\alpha_{3}+\\cdots \\alpha_{n}\\right) v_{1}+\\alpha_{2}\\left(v_{2}-v_{1}\\right)+ \\\\\n\\quad+\\alpha_{n}\\left(v_{n}-v_{1}\\right)\n\\end{array}\n\\]\n\\( \\therefore W \\) is a linear combination of \\( v_{1}, v_{2}-v_{1}, v_{3}-v_{1} \\cdots \\)\n, \\( V_{n}-V_{1} \\) prowing that these vectors spanv.\n(ii) \\( v_{1} ; V_{2}, v_{3} \\ldots v_{A} \\) are linearly independent"